# Machine Learning Operations (MLOps)

## Introducción

La start-up de agregación de plataformas de streaming requiere un sistema de recomendación de películas y series para mejorar la experiencia del usuario y aumentar la retención de clientes. Como Data Scientist, se me ha asignado la tarea de desarrollar un sistema de recomendación de manera integral, desde la recolección y tratamiento de datos hasta el entrenamiento y mantenimiento del modelo de Machine Learning. Sin embargo, los datos disponibles actualmente son inmaduros y requieren una gran cantidad de trabajo de Data Engineer para transformarlos y prepararlos para su uso en el modelo.

## Objetivo

El objetivo de este proyecto es desarrollar un sistema de recomendación de películas y series personalizado para la start-up de agregación de plataformas de streaming. El sistema de recomendación se basará en la similitud de puntuación entre películas y se ordenará según el score de similaridad, devolviendo una lista con los 5 nombres de las películas con mayor puntaje, en orden descendente. El proyecto abarcará todo el ciclo de vida de un proyecto de Machine Learning, desde la recolección y tratamiento de datos hasta el entrenamiento y mantenimiento del modelo de Machine Learning. El resultado final será un MVP que pueda ser implementado en las próximas semanas para mejorar la experiencia del usuario y aumentar la retención de clientes.

## Tecnologías Utilizadas

![Python](https://img.shields.io/badge/Python-3776AB.svg?style=for-the-badge&logo=Python&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
![Seaborn](https://img.shields.io/badge/Seaborn-%2370399F.svg?style=for-the-badge&logo=seaborn&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Google Colab](https://img.shields.io/badge/Google%20Colab-F9AB00.svg?style=for-the-badge&logo=Google-Colab&logoColor=white)
![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=ffffff)
![Render](https://img.shields.io/badge/Render-46E3B7.svg?style=for-the-badge&logo=Render&logoColor=white)

- **Python**: lenguaje de programación principal utilizado en el proyecto.
- **Librerías de Python**: se utilizaron diversas librerías de Python para diferentes tareas en el proyecto como Pandas, Numpy, Datetime, Ast y Json para la limpieza de los datos, Matplotlib y Seaborn para la visualización de datos, así como Scikit-learn para el modelado de Machine Learning
- **Google Colab**: plataforma de Jupyter Notebook basada en la nube que se utilizó para el proceso de ETL (Extracción, Transformación y Carga) de los datos.
- **Visual Studio Code**: un editor de código fuente desarrollado por Microsoft que se utilizó para escribir y editar el código de Python para el desarrollo de las consultas a la API.
- **FastAPI**: un framework de Python para construir APIs web rápidas y escalables.
- **Render**: servicio en la nube utilizado para implementar el modelo de Machine Learning en producción.

## Desarrollo del Proyecto

## ETL

## FastAPI

## Machine Learning

## Recomendaciones

Si deseas replicar este proyecto:

Puedes abrir la carpeta Dataset en Google Drive haciendo clic en el badge de Google Drive a continuación [![Google Drive](https://img.shields.io/badge/Google_Drive-Open-blue?logo=google-drive&style=flat-square)](https://drive.google.com/drive/folders/1uYpitLzf2ZTTltMB8LuqmZY8ctHLLIaV?usp=sharing) haz un shortcut de la carpeta en tu Drive, luego accede a Google Colab mediante el badge de Google Colab a continuación [![Google Colab](https://img.shields.io/badge/Google%20Colab-Open-blue?logo=googlecolab&style=flat-square)](https://colab.research.google.com/drive/1uCYYnTIsagXIYE4fGcCBgTuCBKOjQVQy?usp=sharing) y haz una copia de este mismo notebook. Finalmente, asegúrate de colocar la ruta de la carpeta Dataset en la variable dataset_dir.
